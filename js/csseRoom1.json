{
    "csse": [
        {
            "time": "1:00 PM - 1:15 PM",
            "projectId": "csse-1-115",
            "title": "Software Engineering of Teaching Tools: A Canvas Application",
            "studentName": "Jenny Harston",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Mr. Mark Kochanski",
            "posterLink": "./posters/csse/harston-jenny.jpg",
            "abstract": "Canvas is a website used by instructors and students at UWB to access and manage their courses. Teaching Tools is an application in the early stages of development that integrates with Canvas to provide more functionality for students and faculty. It can be used to simplify connections with external tools such as Google Drive and Microsoft Office, and automate repetitive tasks to increase work efficiency. Current functionality includes features such as setting up course groups with shared Google Drive folders, adding a comment to a group assignment submission that identifies the submitter, and importing course settings from an old section to a new one.\n\nThe majority of the work I did on Teaching Tools was refactoring the back-end Python code. I redesigned the architecture to improve the logic and flow of the program and remove redundancies. The original code did not have well-defined layers for accessing the Canvas and Google APIs or for processing the data. I began by reorganizing the structure so that Canvas related functions were separated from Google related functions. The implementations for Canvas API calls were specific to the current features in Teaching Tools, so if a new feature was to be added, the required API calls would need to be researched and implemented, possibly duplicating work. I wanted to provide a simple way to access the Canvas API, so I added an API wrapper which encapsulates a substantial number of Canvas API calls into a single service. This will help streamline the process of interacting with Canvas and allow for new features to be implemented more quickly. In addition, I created a pure data model layer that stores the data retrieved from Canvas so the data can be more easily processed.\n\nThe work I did created a solid base for future students and developers to build off. The improved architecture is simpler to navigate and more modular, which will make the software easier to develop and maintain. Furthermore, the work I did greatly increased my knowledge and skill in the Python language, in software patterns and architecture, and many other areas of software engineering."
        },
        {
            "time": "1:45 PM - 2:00 PM",
            "projectId": "csse-1-145",
            "title": "Software Engineer Intern @ Cquestip",
            "studentName": "Ahmed Abdullahi",
            "studentMajor": "CSSE",
            "projectType": "Internship - CQuestip Inc.",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/abdullahi-ahmed.png",
            "abstract": "As part of my capstone project, I completed an internship as a Software Engineer Intern at Cqestip, a mentorship startup that is focused on creating a platform for students to enhance their learning and career opportunities. During my internship, I contributed to the development of Nurture, a product aimed at providing students from middle school to college and beyond with an education portfolio that tracks their achievements, activities, and accomplishments.\n\nNurture will be used to match students with internships and other opportunities based on their criteria, making it easier for them to find relevant options. To develop Nurture, I collaborated with a team of four developers and other interns. We began by identifying the essential features of the application and designing user stories and UML diagrams to meet the intended use. After finalizing the design, we worked on the backend, which involved creating a database, designing API routes, and implementing business logic following the MVC architecture. As part of this process, I ensured that the API was designed according to specification and performed necessary software testing using JUnit and integration testing. I also designed the backend architecture with scalability and performance as key considerations, achieving scalability through horizontal scaling.\n\nWe used Spring Boot, Mongo DB, and JWT for the backend user interactions and data for Nurture. However, we faced performance issues during development, and we had to switch from Postgres to MongoDB to address the slow execution of queries on JsonB columns. Using embedded documents in MongoDB allowed us to achieve the same design without drawbacks.\n\nWhile Nurture is still in the prototype phase, it is a critical component of Cqestip, and it will provide many students with the opportunity to pursue higher education and career goals. The application will enable students to showcase their skills and accomplishments to reach their full potential. In summary, this project allowed me to gain an understanding of software design from the ground up and provided valuable industry-level experience.\n\nMy internship at Cqestip was a great opportunity to apply my classroom learning in a real-world application."
        },
        {
            "time": "2:00 PM - 2:15 PM",
            "projectId": "csse-1-200",
            "title": "Automating Network Infrastructure at Cisco Meraki",
            "studentName": "Liam Morrison",
            "studentMajor": "CSSE",
            "projectType": "Internship - Cisco/Meraki",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/morrison-liam-peter-hampton.jpg",
            "abstract": "During my internship at Cisco Meraki, I worked on three projects. The first project was a setup automation for a CML (Cisco Modeling Labs) Interview, where I utilized the python programming language and a tool known as Apache Airflow. The purpose of this project was to reduce the time spent by the SRE Network team on the monotonous setup of the CML Interview environment. Upon completion of the automation, it was able to spin up an EC2 instance in AWS, import and start a CML lab on the CML server, and configure both the EC2 instance and a machine in the CML lab with a VPN tunnel. From this project I learned how to use Apache Airflow and utilize python to interact with several endpoints and services.\n\nThe second project was to add python scripts to a VPC IPAM tool to avoid overlap in IPv4 and IPv6 address in the hybrid cloud infrastructure. Currently within Meraki’s hybrid cloud infrastructure there was trouble with easily managing and guaranteeing no overlap of IPv4 and IPv6 addresses for VPCs. The python scripts I added performed Terraform file generation for users who needed VPCs, by first checking the sources of truth like Netbox and AWS, it guaranteed that there would not be overlap among IPv4 or IPv6 for the newly generated VPC.\n\nThe final project I worked on was a general Prometheus exporter that could run and consume any network infrastructure test written in python or ruby and expose data transposed for Prometheus on an endpoint for Prometheus to scrape. This project was not completely integrated by the time I left; however, the main exporter was built. The exporter allowed for tests written in python to be run, transposed for Prometheus, and then made available to Prometheus through a HTTP endpoint. The exporter is built in the Golang programming language and deployable via a docker container for portability and ease of use. This exporter will allow the SRE Network team flexibility in writing network infrastructure tests that can be consumed by Prometheus, by not having to write a separate exporter for each test written."
        },
        {
            "time": "2:15 PM - 2:30 PM",
            "projectId": "csse-1-215",
            "title": "Employment @ Spring Venture Group(SVG)",
            "studentName": "Ethan Yang",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/yang-ethan-2.png",
            "abstract": "The purpose of this project was to streamline the process of managing Spring Venture Group (SVG) employee data by automating the identification and updating of employee records based on role changes.\n\n The project began with an analysis of the existing employee data management system and the challenges faced by HR personnel in keeping up with role changes and other updates. We identified a need for a more automated and efficient system that could process employee data in real-time and update records accordingly. I developed a solution when we realized that there were already methods that read employee data from kinesis streams that were called daily. Using this, I decided to implement something similar.\n\n Using Kinesis, we developed a stream processing system that could receive and process data from HR databases through Lambda functions. The system used a set of rules to identify changes in employee roles and other key data points, and automatically updated employee records accordingly.\n\n Throughout the development process, we placed a strong emphasis on testing and verification to ensure that the system was reliable and accurate. We developed a comprehensive set of test cases to cover all possible scenarios, and implemented automated testing tools to streamline the process. We also conducted extensive manual testing to ensure that the system robust and solid.\n\n The result of this project is a highly efficient and automated employee data management system that has significantly reduced the workload of HR personnel at SVG. By using Lambda functions to process data from Kinesis in real-time, the system is able to quickly and accurately update employee records and limit access to sensitive data as well as reducing the risk of errors and delays. This project has been released and is currently being used at the time of this writing.\n\n In conclusion, this capstone project demonstrates the value of stream processing systems in managing large volumes of data in real-time. The use of Kinesis to build a highly efficient and automated employee data management system provides a solid foundation for development in this area."
        },
        {
            "time": "2:30 PM - 2:45 PM",
            "projectId": "csse-1-230",
            "title": "Developing Analysis Tool for Efficient Delta Vision (DV) File Processing",
            "studentName": "Ryota Theodora",
            "studentMajor": "CSSE",
            "projectType": "UWB CSS Faculty Research",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/theodora-ryota.jpg",
            "abstract": "The Yeast Analysis is an ongoing project that aims to develop a more versatile and robust tool for yeast data analysis. The project involves close collaboration between biology researchers and software developers to ensure that the program meets the specific features and standards required by the biology research community. The tool is used to analyze images of yeast cells under the microscope, providing data that can be exported to a CSV file for further analysis.\n\n The original version of the program was limited in its ability to read and process different types of files, as it was designed specifically to analyze a single type of file format, TIF images extracted from DV files. The new version of the program will be able to read and process multiple DV files directly without the need for extraction into TIF images. This development will make the program more versatile and user-friendly.\n\n Achieving this, the refactoring process will involve restructuring the code base and removing any redundancies or duplicated codes. The project requires clear communication between user community and provides accurate and reliable results.\n\n Overall, the new version of the tool shows significant improvement over the original, offering a more flexible and user- friendly tool for yeast data analysis, and facilitating research in this field."
        },
        {
            "time": "2:45 PM - 3:00 PM",
            "projectId": "csse-1-245",
            "title": "Token Management System Cryptocurrency Payment System Using Algorand's Blockchain",
            "studentName": "Maxwell Fischer",
            "studentMajor": "CSSE",
            "projectType": "Individual Project - Student Defined",
            "facultyAdvisor": "Dr. Brent Lagesse",
            "posterLink": "./posters/csse/fischer-maxwell.png",
            "abstract": "Cryptocurrency has been developing as a technology for the past decade, it uses a novel form of network verification and provides an immutable ledger while promising to quantify everyday objects and experiences. Cryptocurrency has evolved with the introduction of smart contracts, which allow business logic to be programmed into the network. My project utilizes the Algorand blockchain in order to provide a web platform for tokenization so that users can gamify scheduling and project management.\n\n During the course of the project, I worked in a full-stack capacity. The back-end was implemented using the Django Python web framework with an SQLite database, and the front-end was implemented using the Bulma CSS Framework. Users can create, transfer, and view asset transactions on the Algorand blockchain. For the project, Algorand’s Python SDK was used in conjunction with Django to interact with the blockchain from the back-end in order to submit transactions. Furthermore a smart contract was deployed, written in Algorand’s assembly language, in order to increase functionality of the created assets for the user. Bulma CSS styling was combined with Django’s templating system for serving dynamic content.\n\n Through this project I have learned and been exposed to a large amount of new technologies. I wrote a connected front and back end using Django and Bulma, and also integrated blockchain technology with my web application. I developed a platform for tokenization, and there are many ways to continue building and growing the application including developing the UI/UX experience and expanding the database models."
        }                  
    ]
}